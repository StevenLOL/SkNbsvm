{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of NBsvm on Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports + Data to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from loadData import loadLabeled\n",
    "# Data contains the list of text and Class the corresponding Label (1=POS, 0=NEG)\n",
    "data, Class = loadLabeled('./train')\n",
    "# print \"Label: \",Class[0],'\\n',\"Text: \", data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docteur petiot starring michel serrault is a brutal story about a brutal man a doctor who heals the sick in occupied france even if their ability to compensate is not there yet he preys on the weakest amidst the populace the imagery and cinematography are superb and lend an additional macabre feeling to this complex story he is the perfect psychopath seductive and altruistic intelligent and caring calculating and murderous a movie certain not to be forgotten soon by the viewer kudos to mr serrault for his chilling portrayal\n"
     ]
    }
   ],
   "source": [
    "from loadData import review_to_wordlist\n",
    "\n",
    "data_cleaned = []\n",
    "for i in xrange(len(data)):\n",
    "    data_cleaned.append(\" \".join(review_to_wordlist(data[i])))\n",
    "print data_cleaned[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "test_ratio = 0.4\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data_cleaned, Class, test_size = test_ratio, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Test NBSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### a - CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,2),binary=True)\n",
    "count_vect.fit(data_train)\n",
    "count_matrix = count_vect.transform(data_train)\n",
    "count_test = count_vect.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - NBmatrix v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.63015890121 s\n"
     ]
    }
   ],
   "source": [
    "from nbsvm import NBmatrix\n",
    "t0 = time()\n",
    "nbmat = NBmatrix(alpha=1.0,bina=True,n_jobs=1)\n",
    "nbmat.fit(count_matrix,labels_train)\n",
    "nbm_test = nbmat.transform(count_test)\n",
    "nbm_data = nbmat.transform(count_matrix)\n",
    "print \"Time: \",time()-t0,'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - NBmatrix v1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Test with Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_reg:  0.894451962111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import sklearn.metrics as met\n",
    "\n",
    "Log_reg = LR(C=30,penalty = 'l2', dual = True, random_state = 0)\n",
    "Log_reg.fit(nbm_data,labels_train)\n",
    "print \"Log_reg: \", met.precision_score(labels_test, Log_reg.predict(nbm_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
